<!DOCTYPE html>
<html>
<head>
    <title>3D Window - Head Tracking</title>
    <style>
        body { margin: 0; overflow: hidden; background: #000; font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif; }
        canvas { display: block; }
        
        #ui-overlay {
            position: absolute; top: 20px; left: 20px; color: white;
            background: rgba(0,0,0,0.7); padding: 15px; border-radius: 8px;
            pointer-events: none; border: 1px solid #444;
        }

        #loading-container {
            position: absolute; top: 50%; left: 50%;
            transform: translate(-50%, -50%);
            text-align: center; color: white;
        }
        #progress-bar-bg {
            width: 250px; height: 6px; background: #222;
            border-radius: 3px; margin-top: 15px; overflow: hidden;
        }
        #progress-bar-fill {
            width: 0%; height: 100%; background: #00ffcc;
            transition: width 0.3s; box-shadow: 0 0 10px #00ffcc;
        }

        #video-preview {
            position: absolute; bottom: 20px; right: 20px;
            width: 160px; border-radius: 8px; border: 2px solid #00ffcc;
            transform: scaleX(-1); /* Mirror view */
        }
    </style>
</head>
<body>

    <div id="ui-overlay">
        <div style="font-weight: bold; margin-bottom: 5px;">3D Holographic Window</div>
        <div style="font-size: 12px; opacity: 0.8;">Move your head to look around the object.</div>
    </div>

    <div id="loading-container">
        <div id="status-text">Initializing AI...</div>
        <div id="progress-bar-bg"><div id="progress-bar-fill"></div></div>
    </div>

    <video id="webcam" style="display:none;" autoplay playsinline></video>
    <video id="video-preview" autoplay playsinline></video>

    <script type="importmap">
        {
            "imports": {
                "three": "https://unpkg.com/three@0.160.0/build/three.module.js",
                "three/addons/": "https://unpkg.com/three@0.160.0/examples/jsm/"
            }
        }
    </script>

    <script type="module">
        import * as THREE from 'three';
        import { GLTFLoader } from 'three/addons/loaders/GLTFLoader.js';
        import { FaceLandmarker, FilesetResolver } from "https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.3";

        // --- CALIBRATION ---
        const SCREEN_WIDTH_CM = 35; // Change this to your laptop's screen width
        const SCREEN_HEIGHT_CM = 20;
        const LERP_FACTOR = 0.15; // Lower = smoother but laggier. Higher = snappier but jittery.

        let rawHeadPos = { x: 0, y: 0, z: 50 };
        let smoothedHeadPos = { x: 0, y: 0, z: 50 };

        // --- THREE.JS SCENE SETUP ---
        const scene = new THREE.Scene();
        const renderer = new THREE.WebGLRenderer({ antialias: true });
        renderer.setSize(window.innerWidth, window.innerHeight);
        renderer.setPixelRatio(window.devicePixelRatio);
        document.body.appendChild(renderer.domElement);

        const camera = new THREE.PerspectiveCamera(); 
        
        // Lighting
        const ambientLight = new THREE.AmbientLight(0xffffff, 0.8);
        scene.add(ambientLight);
        const spotLight = new THREE.PointLight(0xffffff, 500);
        spotLight.position.set(0, 20, 10);
        scene.add(spotLight);

        // Virtual Box (The "Room")
        const boxSize = 50;
        const grid = new THREE.GridHelper(boxSize, 20, 0x00ffcc, 0x222222);
        grid.rotation.x = Math.PI / 2;
        grid.position.z = -boxSize / 2;
        scene.add(grid);

        // Load your model.glb
        let model;
        const loader = new GLTFLoader();
        const progressBar = document.getElementById('progress-bar-fill');
        const statusText = document.getElementById('status-text');

        loader.load('model.glb', 
            (gltf) => {
                model = gltf.scene;
                // Center and Scale
                const box = new THREE.Box3().setFromObject(model);
                const size = box.getSize(new THREE.Vector3());
                const scale = 15 / Math.max(size.x, size.y, size.z);
                model.scale.set(scale, scale, scale);
                
                model.position.z = -15;
                scene.add(model);
                document.getElementById('loading-container').style.display = 'none';
            },
            (xhr) => {
                if (xhr.lengthComputable) {
                    const percent = (xhr.loaded / xhr.total) * 100;
                    progressBar.style.width = percent + '%';
                    statusText.innerText = "Loading Model...";
                }
            }
        );

        // --- MEDIAPIPE AI SETUP ---
        const video = document.getElementById("webcam");
        const videoPreview = document.getElementById("video-preview");
        let faceLandmarker;

        async function initAI() {
            const vision = await FilesetResolver.forVisionTasks("https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.3/wasm");
            faceLandmarker = await FaceLandmarker.createFromOptions(vision, {
                baseOptions: { modelAssetPath: `https://storage.googleapis.com/mediapipe-models/face_landmarker/face_landmarker/float16/1/face_landmarker.task` },
                runningMode: "VIDEO"
            });
            
            const stream = await navigator.mediaDevices.getUserMedia({ video: true });
            video.srcObject = stream;
            videoPreview.srcObject = stream;
            video.addEventListener("loadeddata", () => predict());
        }

        function predict() {
            const results = faceLandmarker.detectForVideo(video, performance.now());
            if (results.faceLandmarks && results.faceLandmarks.length > 0) {
                const face = results.faceLandmarks[0];
                const eyePoint = face[1]; // Tip of nose / center
                
                // Map to CM
                rawHeadPos.x = (eyePoint.x - 0.5) * -SCREEN_WIDTH_CM;
                rawHeadPos.y = (eyePoint.y - 0.5) * -SCREEN_HEIGHT_CM;
                
                // Estimate depth based on eye distance
                const eyeDist = Math.sqrt(Math.pow(face[33].x - face[263].x, 2) + Math.pow(face[33].y - face[263].y, 2));
                rawHeadPos.z = 15 / (eyeDist + 0.01);
            }
            requestAnimationFrame(predict);
        }

        // --- ANIMATION LOOP ---
        function animate() {
            // Apply Smoothing (LERP)
            smoothedHeadPos.x += (rawHeadPos.x - smoothedHeadPos.x) * LERP_FACTOR;
            smoothedHeadPos.y += (rawHeadPos.y - smoothedHeadPos.y) * LERP_FACTOR;
            smoothedHeadPos.z += (rawHeadPos.z - smoothedHeadPos.z) * LERP_FACTOR;

            // Off-Axis Matrix calculation
            const n = smoothedHeadPos.z;
            const f = 2000;
            const l = -SCREEN_WIDTH_CM / 2 - smoothedHeadPos.x;
            const r =  SCREEN_WIDTH_CM / 2 - smoothedHeadPos.x;
            const b = -SCREEN_HEIGHT_CM / 2 - smoothedHeadPos.y;
            const t =  SCREEN_HEIGHT_CM / 2 - smoothedHeadPos.y;

            camera.projectionMatrix.makePerspective(l, r, t, b, n, f);
            camera.position.set(smoothedHeadPos.x, smoothedHeadPos.y, smoothedHeadPos.z);
            camera.lookAt(smoothedHeadPos.x, smoothedHeadPos.y, 0);

            if (model) model.rotation.y += 0.005;

            renderer.render(scene, camera);
            requestAnimationFrame(animate);
        }

        window.addEventListener('resize', () => {
            renderer.setSize(window.innerWidth, window.innerHeight);
        });

        initAI();
        animate();
    </script>
</body>
</html>
